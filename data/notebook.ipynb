{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "import plotly.graph_objects as go\n",
    "import plotly.io as pio\n",
    "\n",
    "\n",
    "from log_parser import *\n",
    "from odrive_utils import *\n",
    "from figures import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Logs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# config\n",
    "log_dir = \"logs\"\n",
    "generate_html = True\n",
    "offline = False\n",
    "show_figures = False\n",
    "min_log_size_kb = 1\n",
    "csv_logs = False\n",
    "dark_theme = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get paths\n",
    "if csv_logs:\n",
    "    log_ext = \"txt\"\n",
    "    logParserFunc = parseCSVFile\n",
    "else:\n",
    "    log_ext = \"bin\"\n",
    "    logParserFunc = parseBinaryFile\n",
    "if dark_theme:\n",
    "    pio.templates.default = \"plotly_dark\"\n",
    "else:\n",
    "    pio.templates.default = \"plotly_white\"\n",
    "\n",
    "\n",
    "paths = getLogsByExtension(log_dir, log_ext)\n",
    "paths = filterFilesBySize(paths, min_log_size_kb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create dataframes\n",
    "dfs = []\n",
    "\n",
    "for path in paths:\n",
    "    _, df = logParserFunc(path)\n",
    "    if df is None:\n",
    "        continue\n",
    "    postProcessDataframe(df)\n",
    "    df.filename = os.path.basename(path)\n",
    "    addNormalizedColumns(df)\n",
    "    dfs.append(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create per Log Graphs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create graphs\n",
    "figure_funcs = [\n",
    "    getRPMFigure,\n",
    "    # getRPMAndActuatorFigure,\n",
    "    getVehicleSpeedFigure,\n",
    "    # getShiftRatioAndAcuatorFigure,\n",
    "    # getShiftRatioFigure,\n",
    "    # getVelocityCommandFigure,\n",
    "    # getShadowCountFigure,\n",
    "    # getEngineVsWheelFigure,\n",
    "    # getEverythingFigure,\n",
    "    # getVoltageAndCurrentFigure,\n",
    "    getCarPositionFigure,\n",
    "]\n",
    "\n",
    "all_figs_by_log = []\n",
    "\n",
    "for df in dfs:\n",
    "    figs = []\n",
    "    for figure_func in figure_funcs:\n",
    "        figs.append(figure_func(df))\n",
    "    all_figs_by_log.append(figs)\n",
    "\n",
    "if generate_html:\n",
    "    for path, figs_by_log in zip(paths, all_figs_by_log):\n",
    "        filename_without_ext = os.path.splitext(os.path.basename(path))[0]\n",
    "        html_path = f\"graphs/{filename_without_ext}.html\"\n",
    "        figuresToHTML(figs_by_log, html_path, offline=offline, dark_theme=dark_theme)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from IPython.display import clear_output\n",
    "\n",
    "show_figures = True\n",
    "if show_figures:\n",
    "    dropdown = widgets.Dropdown(options=paths, value=paths[-1])\n",
    "\n",
    "    def onDropdownChange(change):\n",
    "        if change[\"type\"] == \"change\" and change[\"name\"] == \"value\":\n",
    "            clear_output()\n",
    "            idx = paths.index(change[\"new\"])\n",
    "            printErrorTimes(dfs[idx], ErrorType.MOTOR)\n",
    "            display(dropdown)\n",
    "            for fig in all_figs_by_log[idx]:\n",
    "                fig.show()\n",
    "\n",
    "    idx = -1\n",
    "    dropdown.observe(onDropdownChange)\n",
    "    printErrorTimes(dfs[idx], ErrorType.MOTOR)\n",
    "    display(dropdown)\n",
    "    for fig in all_figs_by_log[idx]:\n",
    "        fig.show()\n",
    "print(np.max(df[\"control_cycle_start_s\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create Group Graphs (By Graph Type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "figure_names_and_funcs = [\n",
    "    (\"rpm\", getRPMFigure),\n",
    "    (\"rpm-and-actuator\", getRPMAndActuatorFigure),\n",
    "    (\"vehicle-speed\", getVehicleSpeedFigure),\n",
    "    (\"shift-ratio-and-acuator\", getShiftRatioAndAcuatorFigure),\n",
    "    (\"velocity-command\", getVelocityCommandFigure),\n",
    "    (\"shadow-count\", getShadowCountFigure),\n",
    "    (\"shift-ratio\", getShiftRatioFigure),\n",
    "    (\"engine-vs-wheel\", getEngineVsWheelFigure),\n",
    "]\n",
    "all_figs_by_type = []\n",
    "for name, func in figure_names_and_funcs:\n",
    "    figs_by_type = []\n",
    "    for df in dfs:\n",
    "        figs_by_type.append(func(df))\n",
    "    all_figs_by_type.append((name, figs_by_type))\n",
    "\n",
    "if generate_html:\n",
    "    for figs_by_type in all_figs_by_type:\n",
    "        filename_without_ext = os.path.splitext(os.path.basename(path))[0]\n",
    "        html_path = f\"graphs/all-{figs_by_type[0]}.html\"\n",
    "        figuresToHTML(figs_by_type[1], html_path, offline=offline)\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scratch Work"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "header, df = parseBinaryFile(\"logs/log_2023-04-23_18-30-50.bin\")\n",
    "max_time_idx = df[\"control_cycle_start_us\"].argmax()\n",
    "if max_time_idx != len(df) - 1:\n",
    "    dts = np.cumsum(df[\"control_cycle_dt_us\"].iloc[max_time_idx + 1 :])\n",
    "\n",
    "    overflow_start_time_us = df[\"control_cycle_start_us\"].iloc[max_time_idx]\n",
    "    overflow_stop_time_us = df[\"control_cycle_stop_us\"].iloc[max_time_idx]\n",
    "    df[\"control_cycle_start_us\"].iloc[max_time_idx + 1 :] = df[\n",
    "        \"control_cycle_start_us\"\n",
    "    ].iloc[max_time_idx + 1 :] + (overflow_start_time_us + dts)\n",
    "    df[\"control_cycle_stop_us\"].iloc[max_time_idx + 1 :] = df[\n",
    "        \"control_cycle_stop_us\"\n",
    "    ].iloc[max_time_idx + 1 :] + (overflow_stop_time_us + dts)\n",
    "dumpToBinary(\"out.bin\", header, df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def winter_low(cutoff_freq, sample_time, x0, x1, x2, y1, y2, print_coeff=False):\n",
    "    \"\"\"Filters a data sample based on two past unfiltered and filtered data samples.\n",
    "\n",
    "    2nd order low pass, single pass butterworth filter presented in Winter2009.\n",
    "\n",
    "    Parameters\n",
    "    ==========\n",
    "    cuttoff_freq: float\n",
    "        The desired lowpass cutoff frequency in Hertz.\n",
    "    sample_time: floaat\n",
    "        The difference in time between the current time and the previous time.\n",
    "    x0 : float\n",
    "        The current unfiltered signal, x_i\n",
    "    x1 : float\n",
    "        The unfiltered signal at the previous sampling time, x_i-1.\n",
    "    x2 : float\n",
    "        The unfiltered signal at the second previous sampling time, x_i-2.\n",
    "    y1 : float\n",
    "        The filtered signal at the previous sampling time, y_i-1.\n",
    "    y2 : float\n",
    "        The filtered signal at the second previous sampling time, y_i-2.\n",
    "\n",
    "    \"\"\"\n",
    "    sampling_rate = 1 / sample_time  # Hertz\n",
    "\n",
    "    correction_factor = 1.0  # 1.0 for a single pass filter\n",
    "\n",
    "    corrected_cutoff_freq = (\n",
    "        np.tan(np.pi * cutoff_freq / sampling_rate) / correction_factor\n",
    "    )  # radians\n",
    "\n",
    "    K1 = np.sqrt(2) * corrected_cutoff_freq\n",
    "    K2 = corrected_cutoff_freq**2\n",
    "\n",
    "    a0 = K2 / (1 + K1 + K2)\n",
    "    a1 = 2 * a0\n",
    "    a2 = a0\n",
    "\n",
    "    K3 = a1 / K2\n",
    "\n",
    "    b1 = -a1 + K3\n",
    "    b2 = 1 - a1 - K3\n",
    "\n",
    "    if print_coeff:\n",
    "        print(\"num:\", a0, a1, a2)\n",
    "        print(\"dem:\", 1.0, -b1, -b2)\n",
    "\n",
    "    return a0 * x0 + a1 * x1 + a2 * x2 + b1 * y1 + b2 * y2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0]\n",
    "df = trimDataFrame(df, start_s=37, end_s=160)\n",
    "dt_s = np.array(df[\"control_cycle_dt_us\"]) / 1e6\n",
    "t_s = np.array(df[\"control_cycle_start_us\"]) / 1e6\n",
    "sd_rpm = np.array(df[\"secondary_rpm\"])\n",
    "filt_sd_rpm = np.zeros_like(sd_rpm)\n",
    "\n",
    "for i in range(2, len(t_s)):\n",
    "    filt_sd_rpm[i] = winter_low(\n",
    "        0.8,\n",
    "        dt_s[i],\n",
    "        sd_rpm[i],\n",
    "        sd_rpm[i - 1],\n",
    "        sd_rpm[i - 2],\n",
    "        filt_sd_rpm[i - 1],\n",
    "        filt_sd_rpm[i - 2],\n",
    "    )\n",
    "\n",
    "px.line(x=t_s, y=[sd_rpm, filt_sd_rpm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0]\n",
    "df = trimDataFrame(df, start_s=37, end_s=160)\n",
    "df[\"secondary_freq_mag\"] = np.abs(np.fft.fft(df[\"secondary_rpm\"]))\n",
    "df[\"engine_freq_mag\"] = np.abs(np.fft.fft(df[\"engine_rpm\"]))\n",
    "df[\"freqs\"] = np.fft.fftfreq(len(df), np.mean(df[\"control_cycle_dt_us\"] / 1e6))\n",
    "\n",
    "# px.line(df, x=\"control_cycle_start_s\", y=\"secondary_rpm\")\n",
    "px.line(df, x=\"freqs\", y=\"engine_freq_mag\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dfs[0]\n",
    "dt_s = np.array(df[\"control_cycle_dt_us\"]) / 1e6\n",
    "t_s = np.array(df[\"control_cycle_start_us\"]) / 1e6\n",
    "eg_rpm = np.array(df[\"engine_rpm\"])\n",
    "filt_eg_rpm = np.zeros_like(eg_rpm)\n",
    "exp_filt_eg_rpm = np.zeros_like(eg_rpm)\n",
    "vel_cmd = np.array(df[\"velocity_command\"])\n",
    "deriv_vel_cmd = np.array(df[\"velocity_command\"])\n",
    "\n",
    "alpha = 0.7\n",
    "for i in range(2, len(t_s)):\n",
    "    filt_eg_rpm[i] = winter_low(\n",
    "        1.2,\n",
    "        dt_s[i],\n",
    "        eg_rpm[i],\n",
    "        eg_rpm[i - 1],\n",
    "        eg_rpm[i - 2],\n",
    "        filt_eg_rpm[i - 1],\n",
    "        filt_eg_rpm[i - 2],\n",
    "    )\n",
    "    exp_filt_eg_rpm[i] = alpha * eg_rpm[i] + (1 - alpha) * exp_filt_eg_rpm[i - 1]\n",
    "\n",
    "d_eg_rpm = np.diff(eg_rpm) / dt_s[1:]\n",
    "d_filt_eg_rpm = np.diff(filt_eg_rpm) / dt_s[1:]\n",
    "KD = 0.01\n",
    "for i in range(len(t_s) - 1):\n",
    "    deriv_vel_cmd[i] = vel_cmd[i] + d_filt_eg_rpm[i] * KD\n",
    "\n",
    "d_exp_filt_eg_rpm = np.diff(exp_filt_eg_rpm) / dt_s[1:]\n",
    "px.line(x=t_s, y=[eg_rpm, filt_eg_rpm])\n",
    "# px.line(x=t_s[1:], y=[d_eg_rpm, d_filt_eg_rpm,d_exp_filt_eg_rpm])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "px.line(df, x=\"control_cycle_start_s\", y=\"engine_count\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "e7370f93d1d0cde622a1f8e1c04877d8463912d04d973331ad4851f04de6915a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
